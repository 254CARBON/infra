apiVersion: v1
kind: Secret
metadata:
  name: kafka-credentials
  namespace: data-plane
  labels:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/part-of: "254carbon"
type: Opaque
data:
  password: a2Fma2ExMjM= # kafka123
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: kafka-storage
  namespace: data-plane
  labels:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/part-of: "254carbon"
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: standard-local
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: data-plane
  labels:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/part-of: "254carbon"
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: kafka
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kafka
        app.kubernetes.io/part-of: "254carbon"
    spec:
      initContainers:
      - name: init-format-kraft
        image: confluentinc/cp-kafka:7.7.5
        command: ["/bin/bash","-lc"]
        args:
        - |
          set -euo pipefail
          # always cleanup stray 'logs' subdir which breaks KRaft scanning
          rm -rf /var/lib/kafka/data/logs || true
          if [ -f /var/lib/kafka/data/meta.properties ]; then
            echo '[kafka-init] meta.properties exists; skipping format.'
            exit 0
          fi
          CFG=/tmp/kraft-format.properties
          printf '%s\n' \
            'process.roles=broker,controller' \
            'node.id=1' \
            'controller.quorum.voters=1@127.0.0.1:9093' \
            'listeners=PLAINTEXT://:9092,CONTROLLER://:9093' \
            'inter.broker.listener.name=PLAINTEXT' \
            'log.dirs=/var/lib/kafka/data' \
            > "$CFG"
          echo "[kafka-init] Formatting storage with cluster id: ${CLUSTER_ID}"
          kafka-storage format -t "$CLUSTER_ID" -c "$CFG"
          # clean up any stale subdirs created by previous attempts
          rm -rf /var/lib/kafka/data/logs || true
          chown -R 1000:1000 /var/lib/kafka/data || true
        env:
        - name: CLUSTER_ID
          value: "MkU3OEVBNTcwNTJENDM2Qk"
        - name: KAFKA_CLUSTER_ID
          value: "MkU3OEVBNTcwNTJENDM2Qk"
        securityContext:
          runAsNonRoot: false
          runAsUser: 0
        volumeMounts:
        - name: kafka-storage
          mountPath: /var/lib/kafka/data
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/arch
                operator: In
                values:
                - amd64
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 80
            preference:
              matchExpressions:
              - key: role
                operator: In
                values:
                - core
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 60
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: kafka
              topologyKey: kubernetes.io/hostname
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:7.7.5
        imagePullPolicy: IfNotPresent
        command: ["/bin/bash","-lc"]
        args:
        - |
          set -euo pipefail
          exec kafka-server-start /etc/kafka/kraft/server.properties
        ports:
        - name: kafka
          containerPort: 9092
        - name: controller
          containerPort: 9093
        - name: jmx
          containerPort: 9999
        env:
        - name: CONFLUENT_SUPPORT_METRICS_ENABLE
          value: "false"
        - name: JMX_PORT
          value: "9999"
        - name: KAFKA_LOG4J_OPTS
          value: "-Dlog4j.configuration=file:/etc/kafka/log4j-console.properties"
        volumeMounts:
        - name: kafka-storage
          mountPath: /var/lib/kafka/data
        - name: kafka-kraft-config
          mountPath: /etc/kafka/kraft/server.properties
          subPath: server.properties
          readOnly: true
        - name: kafka-log4j-console
          mountPath: /etc/kafka/log4j-console.properties
          subPath: log4j-console.properties
        resources:
          requests:
            cpu: 1200m
            memory: 2Gi
          limits:
            cpu: 2
            memory: 4Gi
        startupProbe:
          tcpSocket:
            port: 9092
          failureThreshold: 30
          periodSeconds: 5
        livenessProbe:
          tcpSocket:
            port: 9092
          initialDelaySeconds: 30
          periodSeconds: 20
          timeoutSeconds: 5
          failureThreshold: 6
        readinessProbe:
          tcpSocket:
            port: 9092
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 3
      - name: kafka-jmx-exporter
        image: bitnami/jmx-exporter:latest
        imagePullPolicy: IfNotPresent
        args:
        - "9404"
        - /etc/jmx-exporter/config.yaml
        ports:
        - name: metrics
          containerPort: 9404
        volumeMounts:
        - name: kafka-jmx-exporter-config
          mountPath: /etc/jmx-exporter
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 300m
            memory: 256Mi
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 65534
        readinessProbe:
          httpGet:
            path: /
            port: metrics
          initialDelaySeconds: 20
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 3
        livenessProbe:
          httpGet:
            path: /
            port: metrics
          initialDelaySeconds: 40
          periodSeconds: 20
          timeoutSeconds: 3
          failureThreshold: 5
      volumes:
      - name: kafka-storage
        persistentVolumeClaim:
          claimName: kafka-storage
      - name: kafka-kraft-config
        configMap:
          name: kafka-kraft-server
      - name: kafka-log4j-console
        configMap:
          name: kafka-log4j-console
      - name: kafka-jmx-exporter-config
        configMap:
          name: kafka-jmx-exporter-config
---
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: data-plane
  labels:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/part-of: "254carbon"
spec:
  selector:
    app.kubernetes.io/name: kafka
  ports:
  - name: kafka
    port: 9092
    targetPort: 9092
  - name: metrics
    port: 9404
    targetPort: 9404
  type: ClusterIP
